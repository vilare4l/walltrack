# Story 10.5.15: Order Priority Queue

## Story Info
- **Epic**: Epic 10.5 - Order Management, Price Oracle & Risk-Based Sizing
- **Status**: ready
- **Priority**: P2 - Medium
- **Story Points**: 3
- **Depends on**: Story 10.5.12 (Retry Worker)

## User Story

**As a** trading system,
**I want** prioriser les ordres EXIT sur les ordres ENTRY,
**So that** les exits protègent le capital avant de prendre de nouvelles positions.

## Acceptance Criteria

### AC 1: Exit Priority
**Given** 5 ordres ENTRY et 3 ordres EXIT sont en attente
**When** le système traite les ordres
**Then** les 3 EXIT sont traités en premier
**And** puis les 5 ENTRY

### AC 2: Within Type Priority
**Given** plusieurs EXIT orders existent
**When** ils sont priorisés
**Then** stop_loss exits passent avant take_profit
**And** les plus anciens passent avant les plus récents

### AC 3: Emergency Override
**Given** un ordre est marqué "emergency"
**When** le système traite les ordres
**Then** cet ordre passe en premier absolu
**And** même avant les autres EXIT

### AC 4: Concurrency Control
**Given** 10 ordres sont en attente
**When** le système les traite
**Then** max 3 ordres sont exécutés en parallèle (configurable)
**And** chaque slot respecte les priorités

### AC 5: Queue Monitoring
**Given** je suis sur le dashboard
**When** je regarde le queue status
**Then** je vois le nombre d'ordres par type et priorité
**And** le temps d'attente estimé
**And** le débit actuel (ordres/minute)

## Technical Specifications

### Priority Queue

**src/walltrack/services/order/priority_queue.py:**
```python
"""Priority queue for order processing."""

import asyncio
from dataclasses import dataclass, field
from datetime import datetime, timezone
from decimal import Decimal
from enum import IntEnum
from typing import Optional
from uuid import UUID
import heapq

import structlog

from walltrack.models.order import Order, OrderType, OrderStatus

logger = structlog.get_logger(__name__)


class OrderPriority(IntEnum):
    """Order priority levels (lower = higher priority)."""
    EMERGENCY = 0
    EXIT_STOP_LOSS = 10
    EXIT_TRAILING = 20
    EXIT_TAKE_PROFIT = 30
    EXIT_MANUAL = 40
    EXIT_OTHER = 50
    ENTRY = 100


@dataclass(order=True)
class PrioritizedOrder:
    """Order wrapper with priority for heap queue."""
    priority: int
    created_at: float = field(compare=True)
    order_id: str = field(compare=False)
    order: Order = field(compare=False)


class OrderPriorityQueue:
    """
    Priority queue for order execution.

    Ensures EXIT orders are processed before ENTRY,
    with sub-priorities within each type.
    """

    def __init__(
        self,
        max_concurrent: int = 3,
    ):
        self._queue: list[PrioritizedOrder] = []
        self._processing: set[str] = set()
        self._max_concurrent = max_concurrent
        self._lock = asyncio.Lock()

        # Metrics
        self._processed_count = 0
        self._total_wait_time = 0.0

    async def enqueue(self, order: Order, emergency: bool = False) -> None:
        """Add order to priority queue."""
        async with self._lock:
            priority = self._calculate_priority(order, emergency)

            item = PrioritizedOrder(
                priority=priority,
                created_at=order.created_at.timestamp(),
                order_id=str(order.id),
                order=order,
            )

            heapq.heappush(self._queue, item)

            logger.debug(
                "order_enqueued",
                order_id=str(order.id)[:8],
                priority=priority,
                queue_size=len(self._queue)
            )

    async def dequeue(self) -> Optional[Order]:
        """Get next order to process (respecting concurrency limit)."""
        async with self._lock:
            if len(self._processing) >= self._max_concurrent:
                return None

            if not self._queue:
                return None

            item = heapq.heappop(self._queue)

            # Track processing
            self._processing.add(item.order_id)

            # Update metrics
            wait_time = datetime.now(timezone.utc).timestamp() - item.created_at
            self._total_wait_time += wait_time
            self._processed_count += 1

            logger.debug(
                "order_dequeued",
                order_id=item.order_id[:8],
                priority=item.priority,
                wait_time=f"{wait_time:.1f}s"
            )

            return item.order

    async def mark_complete(self, order_id: str) -> None:
        """Mark order as completed (release slot)."""
        async with self._lock:
            self._processing.discard(order_id)
            logger.debug("order_processing_complete", order_id=order_id[:8])

    async def remove(self, order_id: str) -> bool:
        """Remove order from queue (if not yet processing)."""
        async with self._lock:
            for i, item in enumerate(self._queue):
                if item.order_id == order_id:
                    del self._queue[i]
                    heapq.heapify(self._queue)
                    logger.debug("order_removed", order_id=order_id[:8])
                    return True
            return False

    def _calculate_priority(self, order: Order, emergency: bool) -> int:
        """Calculate priority value for order."""
        if emergency:
            return OrderPriority.EMERGENCY

        if order.order_type == OrderType.EXIT:
            exit_reason = order.exit_reason or ""

            if "stop_loss" in exit_reason:
                return OrderPriority.EXIT_STOP_LOSS
            elif "trailing" in exit_reason:
                return OrderPriority.EXIT_TRAILING
            elif "take_profit" in exit_reason:
                return OrderPriority.EXIT_TAKE_PROFIT
            elif "manual" in exit_reason or "emergency" in exit_reason:
                return OrderPriority.EXIT_MANUAL
            else:
                return OrderPriority.EXIT_OTHER

        return OrderPriority.ENTRY

    @property
    def queue_size(self) -> int:
        """Current queue size."""
        return len(self._queue)

    @property
    def processing_count(self) -> int:
        """Number of orders currently processing."""
        return len(self._processing)

    @property
    def available_slots(self) -> int:
        """Available processing slots."""
        return max(0, self._max_concurrent - len(self._processing))

    def get_stats(self) -> dict:
        """Get queue statistics."""
        avg_wait = (
            self._total_wait_time / self._processed_count
            if self._processed_count > 0 else 0
        )

        # Count by priority
        priority_counts = {}
        for item in self._queue:
            prio_name = OrderPriority(item.priority).name
            priority_counts[prio_name] = priority_counts.get(prio_name, 0) + 1

        return {
            "queue_size": len(self._queue),
            "processing": len(self._processing),
            "available_slots": self.available_slots,
            "total_processed": self._processed_count,
            "avg_wait_seconds": round(avg_wait, 1),
            "by_priority": priority_counts,
        }


# Singleton
_priority_queue: Optional[OrderPriorityQueue] = None


def get_order_priority_queue() -> OrderPriorityQueue:
    """Get or create priority queue."""
    global _priority_queue
    if _priority_queue is None:
        _priority_queue = OrderPriorityQueue()
    return _priority_queue
```

### Queue-Based Executor

**src/walltrack/services/order/queue_executor.py:**
```python
"""Queue-based order executor with priority processing."""

import asyncio
from typing import Optional

import structlog

from walltrack.models.order import Order, OrderStatus
from walltrack.services.order.priority_queue import (
    OrderPriorityQueue,
    get_order_priority_queue
)
from walltrack.services.order.executor import OrderExecutor, get_order_executor

logger = structlog.get_logger(__name__)


class QueuedOrderExecutor:
    """
    Executes orders from priority queue.

    Manages concurrent execution with priority ordering.
    """

    def __init__(
        self,
        queue: OrderPriorityQueue,
        executor: OrderExecutor,
        process_interval: float = 0.5,
    ):
        self.queue = queue
        self.executor = executor
        self.process_interval = process_interval
        self._running = False
        self._task: Optional[asyncio.Task] = None

    async def start(self) -> None:
        """Start the queue processor."""
        if self._running:
            return

        self._running = True
        self._task = asyncio.create_task(self._process_loop())
        logger.info("queue_executor_started")

    async def stop(self) -> None:
        """Stop the queue processor."""
        self._running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        logger.info("queue_executor_stopped")

    async def submit(self, order: Order, emergency: bool = False) -> None:
        """Submit order to queue for execution."""
        await self.queue.enqueue(order, emergency=emergency)

    async def _process_loop(self) -> None:
        """Main processing loop."""
        while self._running:
            try:
                await self._process_available()
            except Exception as e:
                logger.error("queue_process_error", error=str(e))

            await asyncio.sleep(self.process_interval)

    async def _process_available(self) -> None:
        """Process available orders up to concurrency limit."""
        while self.queue.available_slots > 0:
            order = await self.queue.dequeue()

            if order is None:
                break

            # Execute in background task
            asyncio.create_task(self._execute_order(order))

    async def _execute_order(self, order: Order) -> None:
        """Execute single order and mark complete."""
        try:
            result = await self.executor.execute(order)

            logger.debug(
                "queue_order_executed",
                order_id=str(order.id)[:8],
                success=result.success
            )

        except Exception as e:
            logger.error(
                "queue_order_error",
                order_id=str(order.id)[:8],
                error=str(e)
            )

        finally:
            await self.queue.mark_complete(str(order.id))


# Singleton
_queued_executor: Optional[QueuedOrderExecutor] = None


async def get_queued_executor() -> QueuedOrderExecutor:
    """Get or create queued executor."""
    global _queued_executor

    if _queued_executor is None:
        _queued_executor = QueuedOrderExecutor(
            queue=get_order_priority_queue(),
            executor=await get_order_executor(),
        )

    return _queued_executor


async def start_queued_executor() -> None:
    """Start the queued executor."""
    executor = await get_queued_executor()
    await executor.start()


async def stop_queued_executor() -> None:
    """Stop the queued executor."""
    executor = await get_queued_executor()
    await executor.stop()
```

### Gradio Queue Monitor

**src/walltrack/ui/components/queue_monitor.py:**
```python
"""Queue monitoring component for dashboard."""

import gradio as gr


def create_queue_monitor_panel():
    """Create queue monitoring panel."""

    with gr.Column() as queue_panel:
        gr.Markdown("### Order Queue")

        with gr.Row():
            queue_size = gr.Number(
                label="Queued",
                precision=0,
                interactive=False
            )
            processing = gr.Number(
                label="Processing",
                precision=0,
                interactive=False
            )
            slots = gr.Number(
                label="Available Slots",
                precision=0,
                interactive=False
            )

        with gr.Row():
            avg_wait = gr.Textbox(
                label="Avg Wait Time",
                interactive=False
            )
            total_processed = gr.Number(
                label="Processed (session)",
                precision=0,
                interactive=False
            )

        # Priority breakdown
        with gr.Accordion("By Priority", open=False):
            priority_table = gr.Dataframe(
                headers=["Priority", "Count"],
                datatype=["str", "number"],
                label="Queue by Priority",
                interactive=False,
            )

    return queue_panel, {
        "queue_size": queue_size,
        "processing": processing,
        "slots": slots,
        "avg_wait": avg_wait,
        "total_processed": total_processed,
        "priority_table": priority_table,
    }


async def update_queue_monitor():
    """Update queue monitor display."""
    from walltrack.services.order.priority_queue import get_order_priority_queue

    queue = get_order_priority_queue()
    stats = queue.get_stats()

    # Format priority table
    priority_rows = [
        [prio, count]
        for prio, count in stats["by_priority"].items()
    ]

    avg_wait_text = f"{stats['avg_wait_seconds']:.1f}s"

    return (
        stats["queue_size"],
        stats["processing"],
        stats["available_slots"],
        avg_wait_text,
        stats["total_processed"],
        priority_rows,
    )
```

### Integration with Entry/Exit Services

**src/walltrack/services/order/entry_service.py (modification):**
```python
async def process_signal(self, signal: Signal) -> Optional[Order]:
    """Process signal and submit to queue."""

    # ... existing validation and order creation ...

    # Submit to queue instead of direct execution
    from walltrack.services.order.queue_executor import get_queued_executor

    queued_executor = await get_queued_executor()
    await queued_executor.submit(order)

    logger.info("entry_order_queued", order_id=str(order.id))
    return order
```

**src/walltrack/services/order/exit_service.py (modification):**
```python
async def create_exit_order(
    self,
    position: Position,
    exit_reason: ExitReason,
    sell_percent: Decimal = Decimal("100"),
    emergency: bool = False,
) -> Optional[Order]:
    """Create exit order and submit to queue."""

    # ... existing order creation ...

    # Submit to queue with priority
    from walltrack.services.order.queue_executor import get_queued_executor

    queued_executor = await get_queued_executor()
    await queued_executor.submit(order, emergency=emergency)

    logger.info(
        "exit_order_queued",
        order_id=str(order.id),
        emergency=emergency
    )
    return order
```

## Implementation Tasks

- [ ] Create OrderPriority enum
- [ ] Create PrioritizedOrder wrapper
- [ ] Implement OrderPriorityQueue with heap
- [ ] Add concurrency control
- [ ] Create QueuedOrderExecutor
- [ ] Integrate with Entry/Exit services
- [ ] Add emergency override support
- [ ] Create Gradio queue_monitor panel
- [ ] Add queue statistics
- [ ] Write unit tests
- [ ] Write integration tests

## Definition of Done

- [ ] EXIT orders processed before ENTRY
- [ ] Stop loss exits have highest priority
- [ ] Emergency flag provides absolute priority
- [ ] Concurrency limited to configured max
- [ ] Metrics tracked (wait time, throughput)
- [ ] Gradio shows queue status
- [ ] Full test coverage

## File List

### New Files
- `src/walltrack/services/order/priority_queue.py` - Priority queue
- `src/walltrack/services/order/queue_executor.py` - Queue-based executor
- `src/walltrack/ui/components/queue_monitor.py` - Queue monitor panel
- `tests/unit/services/order/test_priority_queue.py` - Queue tests

### Modified Files
- `src/walltrack/services/order/entry_service.py` - Use queue
- `src/walltrack/services/order/exit_service.py` - Use queue with priority
- `src/walltrack/main.py` - Start/stop queue executor
- `src/walltrack/ui/pages/dashboard.py` - Add queue monitor
