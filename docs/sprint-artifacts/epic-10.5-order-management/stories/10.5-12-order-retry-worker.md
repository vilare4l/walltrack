# Story 10.5.12: Order Retry Worker

## Story Info
- **Epic**: Epic 10.5 - Order Management, Price Oracle & Risk-Based Sizing
- **Status**: ready
- **Priority**: P0 - Critical
- **Story Points**: 5
- **Depends on**: Story 10.5.3 (Order Executor)

## User Story

**As a** trading system,
**I want** un worker qui retry les ordres en échec,
**So that** les ordres temporairement échoués sont réessayés automatiquement.

## Acceptance Criteria

### AC 1: Scheduled Retry Processing
**Given** un Order en status PENDING ou FAILED
**And** next_retry_at <= now
**When** le worker tourne (toutes les 5 secondes)
**Then** l'ordre est réessayé via OrderExecutor
**And** attempt_count est incrémenté

### AC 2: Exponential Backoff
**Given** un ordre échoue à l'attempt 1
**When** retry est schedulé
**Then** next_retry_at = now + 5 secondes
**And** après attempt 2: now + 15 secondes
**And** après attempt 3: now + 45 secondes

### AC 3: Max Attempts Handling
**Given** un ordre atteint max_attempts (3)
**When** il échoue encore
**Then** status passe à CANCELLED (terminal)
**And** une alerte critique est créée
**And** l'ordre n'est plus retry

### AC 4: Priority Processing
**Given** plusieurs ordres en attente de retry
**When** le worker les traite
**Then** les EXIT orders sont traités avant les ENTRY
**And** les ordres plus anciens sont traités en premier
**And** un max de 10 ordres par batch

### AC 5: Concurrent Execution Protection
**Given** le worker tourne
**When** un autre worker instance démarre
**Then** les ordres sont lockés pour éviter double exécution
**And** timeout du lock = 60 secondes

### AC 6: Health Monitoring
**Given** le worker tourne
**When** je check la santé du système
**Then** je vois le nombre d'ordres en attente
**And** le nombre de retries effectués (dernière heure)
**And** le taux de succès des retries

## Technical Specifications

### Retry Worker Service

**src/walltrack/services/order/retry_worker.py:**
```python
"""Worker for processing order retries."""

import asyncio
from datetime import datetime, timezone
from typing import Optional

import structlog

from walltrack.models.order import Order, OrderStatus, OrderType
from walltrack.data.supabase.repositories.order_repo import OrderRepository
from walltrack.services.order.executor import OrderExecutor, get_order_executor

logger = structlog.get_logger(__name__)


class RetryWorker:
    """
    Background worker for processing order retries.

    Runs periodically to check for orders needing retry
    and executes them with proper ordering.
    """

    def __init__(
        self,
        order_repo: OrderRepository,
        executor: OrderExecutor,
        poll_interval: float = 5.0,
        batch_size: int = 10,
        lock_timeout_seconds: int = 60,
    ):
        self.order_repo = order_repo
        self.executor = executor
        self.poll_interval = poll_interval
        self.batch_size = batch_size
        self.lock_timeout = lock_timeout_seconds
        self._running = False
        self._task: Optional[asyncio.Task] = None

        # Metrics
        self._retries_attempted = 0
        self._retries_succeeded = 0
        self._retries_failed = 0

    async def start(self) -> None:
        """Start the retry worker."""
        if self._running:
            logger.warning("retry_worker_already_running")
            return

        self._running = True
        self._task = asyncio.create_task(self._run_loop())
        logger.info("retry_worker_started", interval=self.poll_interval)

    async def stop(self) -> None:
        """Stop the retry worker."""
        self._running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        logger.info("retry_worker_stopped")

    async def _run_loop(self) -> None:
        """Main worker loop."""
        while self._running:
            try:
                await self._process_pending_retries()
            except Exception as e:
                logger.error("retry_worker_error", error=str(e))

            await asyncio.sleep(self.poll_interval)

    async def _process_pending_retries(self) -> None:
        """Process all pending retries."""
        now = datetime.now(timezone.utc)

        # Get orders ready for retry, prioritized
        orders = await self._get_retry_candidates(now)

        if not orders:
            return

        logger.debug("processing_retries", count=len(orders))

        for order in orders:
            # Acquire lock
            if not await self._acquire_lock(order):
                continue

            try:
                await self._process_single_retry(order)
            finally:
                await self._release_lock(order)

    async def _get_retry_candidates(self, now: datetime) -> list[Order]:
        """Get orders ready for retry, prioritized."""
        from walltrack.data.supabase.client import get_supabase_client

        client = await get_supabase_client()

        # Query: status in (PENDING, FAILED), next_retry_at <= now, not locked
        # Order by: type DESC (EXIT before ENTRY), created_at ASC (oldest first)
        result = await client.table("orders") \
            .select("*") \
            .in_("status", [OrderStatus.PENDING.value, OrderStatus.FAILED.value]) \
            .lte("next_retry_at", now.isoformat()) \
            .or_("locked_until.is.null,locked_until.lte." + now.isoformat()) \
            .order("order_type", desc=True) \
            .order("created_at", desc=False) \
            .limit(self.batch_size) \
            .execute()

        return [Order(**row) for row in result.data]

    async def _acquire_lock(self, order: Order) -> bool:
        """Acquire processing lock for order."""
        from walltrack.data.supabase.client import get_supabase_client

        client = await get_supabase_client()
        now = datetime.now(timezone.utc)
        lock_until = datetime.fromtimestamp(
            now.timestamp() + self.lock_timeout,
            tz=timezone.utc
        )

        # Optimistic lock: update only if not locked
        result = await client.table("orders") \
            .update({
                "locked_until": lock_until.isoformat(),
                "locked_by": "retry_worker",
            }) \
            .eq("id", str(order.id)) \
            .or_("locked_until.is.null,locked_until.lte." + now.isoformat()) \
            .execute()

        acquired = len(result.data) > 0

        if acquired:
            logger.debug("lock_acquired", order_id=str(order.id))
        else:
            logger.debug("lock_failed", order_id=str(order.id))

        return acquired

    async def _release_lock(self, order: Order) -> None:
        """Release processing lock for order."""
        from walltrack.data.supabase.client import get_supabase_client

        client = await get_supabase_client()

        await client.table("orders") \
            .update({
                "locked_until": None,
                "locked_by": None,
            }) \
            .eq("id", str(order.id)) \
            .execute()

        logger.debug("lock_released", order_id=str(order.id))

    async def _process_single_retry(self, order: Order) -> None:
        """Process a single order retry."""
        log = logger.bind(
            order_id=str(order.id),
            order_type=order.order_type.value,
            attempt=order.attempt_count + 1
        )

        log.info("processing_retry")
        self._retries_attempted += 1

        # Execute via executor
        result = await self.executor.execute(order)

        if result.success:
            log.info("retry_succeeded")
            self._retries_succeeded += 1

            # Handle position creation/update based on order type
            if order.order_type == OrderType.ENTRY:
                await self._handle_entry_filled(order)
            elif order.order_type == OrderType.EXIT:
                await self._handle_exit_filled(order)

        else:
            log.warning("retry_failed", error=result.error)
            self._retries_failed += 1

            # Check if max attempts reached
            order = await self.order_repo.get_by_id(str(order.id))

            if not order.can_retry:
                await self._handle_max_attempts_reached(order)

    async def _handle_entry_filled(self, order: Order) -> None:
        """Handle successful entry order fill."""
        from walltrack.services.order.entry_service import get_entry_order_service

        # Position creation is handled in entry service
        log = logger.bind(order_id=str(order.id))
        log.info("entry_order_filled_via_retry")

    async def _handle_exit_filled(self, order: Order) -> None:
        """Handle successful exit order fill."""
        from walltrack.services.order.exit_service import get_exit_order_service

        exit_service = await get_exit_order_service()
        await exit_service._process_successful_exit(order)

        log = logger.bind(order_id=str(order.id), position_id=order.position_id)
        log.info("exit_order_filled_via_retry")

    async def _handle_max_attempts_reached(self, order: Order) -> None:
        """Handle order that has exhausted all retries."""
        log = logger.bind(order_id=str(order.id), attempts=order.attempt_count)

        # Create critical alert
        severity = "critical" if order.order_type == OrderType.EXIT else "high"

        from walltrack.services.alerts.alert_service import get_alert_service
        alert_service = await get_alert_service()

        await alert_service.create_alert(
            alert_type="order_failed_permanently",
            severity=severity,
            title=f"{order.order_type.value.upper()} Order Failed - Manual Action Required",
            message=(
                f"Order {order.id} for {order.token_symbol} failed after "
                f"{order.attempt_count} attempts. Last error: {order.last_error}"
            ),
            data={
                "order_id": str(order.id),
                "order_type": order.order_type.value,
                "token": order.token_address,
                "position_id": order.position_id,
                "error": order.last_error,
            },
            requires_action=True,
        )

        log.error("order_failed_permanently")

    def get_metrics(self) -> dict:
        """Get retry metrics."""
        total = self._retries_attempted
        success_rate = (self._retries_succeeded / total * 100) if total > 0 else 0

        return {
            "retries_attempted": self._retries_attempted,
            "retries_succeeded": self._retries_succeeded,
            "retries_failed": self._retries_failed,
            "success_rate_pct": round(success_rate, 1),
        }


# Singleton
_retry_worker: Optional[RetryWorker] = None


async def get_retry_worker() -> RetryWorker:
    """Get or create retry worker."""
    global _retry_worker
    if _retry_worker is None:
        _retry_worker = RetryWorker(
            order_repo=OrderRepository(),
            executor=await get_order_executor(),
        )
    return _retry_worker


async def start_retry_worker() -> None:
    """Start the retry worker."""
    worker = await get_retry_worker()
    await worker.start()


async def stop_retry_worker() -> None:
    """Stop the retry worker."""
    worker = await get_retry_worker()
    await worker.stop()
```

### Order Repository Extensions

**src/walltrack/data/supabase/repositories/order_repo.py (additions):**
```python
async def get_pending_retries(
    self,
    now: datetime,
    limit: int = 10
) -> list[Order]:
    """Get orders ready for retry."""
    result = await self.client.table("orders") \
        .select("*") \
        .in_("status", [OrderStatus.PENDING.value, OrderStatus.FAILED.value]) \
        .lte("next_retry_at", now.isoformat()) \
        .or_(f"locked_until.is.null,locked_until.lte.{now.isoformat()}") \
        .order("order_type", desc=True) \
        .order("created_at", desc=False) \
        .limit(limit) \
        .execute()

    return [Order(**row) for row in result.data]


async def get_pending_count(self) -> int:
    """Get count of orders pending retry."""
    now = datetime.now(timezone.utc)

    result = await self.client.table("orders") \
        .select("id", count="exact") \
        .in_("status", [OrderStatus.PENDING.value, OrderStatus.FAILED.value]) \
        .lte("next_retry_at", now.isoformat()) \
        .execute()

    return result.count or 0


async def get_retry_stats(self, hours: int = 1) -> dict:
    """Get retry statistics for the last N hours."""
    from datetime import timedelta

    cutoff = datetime.now(timezone.utc) - timedelta(hours=hours)

    # Get all orders modified in timeframe
    result = await self.client.table("orders") \
        .select("status, attempt_count") \
        .gte("updated_at", cutoff.isoformat()) \
        .gt("attempt_count", 0) \
        .execute()

    total = len(result.data)
    succeeded = sum(1 for r in result.data if r["status"] == OrderStatus.FILLED.value)
    failed = sum(1 for r in result.data if r["status"] == OrderStatus.CANCELLED.value)
    pending = total - succeeded - failed

    return {
        "total_retries": total,
        "succeeded": succeeded,
        "failed": failed,
        "pending": pending,
        "success_rate_pct": (succeeded / total * 100) if total > 0 else 0,
    }
```

### Database Migration for Locking

**migrations/V9__orders.sql (addition to existing):**
```sql
-- Add locking columns for retry worker
ALTER TABLE walltrack.orders ADD COLUMN IF NOT EXISTS locked_until TIMESTAMPTZ;
ALTER TABLE walltrack.orders ADD COLUMN IF NOT EXISTS locked_by VARCHAR(50);

CREATE INDEX IF NOT EXISTS idx_orders_retry_candidates
ON walltrack.orders(status, next_retry_at, locked_until)
WHERE status IN ('pending', 'failed');
```

### Application Startup Integration

**src/walltrack/main.py (modification):**
```python
"""Main application entry point."""

import asyncio
import structlog

from walltrack.services.order.retry_worker import start_retry_worker, stop_retry_worker

logger = structlog.get_logger(__name__)


async def startup() -> None:
    """Application startup tasks."""
    logger.info("application_starting")

    # Start background workers
    await start_retry_worker()

    logger.info("application_started")


async def shutdown() -> None:
    """Application shutdown tasks."""
    logger.info("application_stopping")

    # Stop background workers
    await stop_retry_worker()

    logger.info("application_stopped")
```

### Gradio Health Component

**src/walltrack/ui/components/system_health.py:**
```python
"""System health display including retry worker status."""

import gradio as gr


def create_system_health_panel():
    """Create system health panel."""

    with gr.Column() as health_panel:
        gr.Markdown("### System Health")

        with gr.Row():
            worker_status = gr.Textbox(
                label="Retry Worker",
                interactive=False
            )
            pending_orders = gr.Number(
                label="Pending Retries",
                precision=0,
                interactive=False
            )

        with gr.Row():
            retries_1h = gr.Number(
                label="Retries (1h)",
                precision=0,
                interactive=False
            )
            success_rate = gr.Textbox(
                label="Success Rate",
                interactive=False
            )

        with gr.Accordion("Retry Details", open=False):
            retry_table = gr.Dataframe(
                headers=["Order ID", "Type", "Token", "Attempts", "Next Retry"],
                datatype=["str", "str", "str", "number", "str"],
                label="Pending Retries",
                interactive=False
            )

    return health_panel, {
        "worker_status": worker_status,
        "pending_orders": pending_orders,
        "retries_1h": retries_1h,
        "success_rate": success_rate,
        "retry_table": retry_table,
    }


async def update_system_health():
    """Update system health display."""
    from walltrack.services.order.retry_worker import get_retry_worker
    from walltrack.data.supabase.repositories.order_repo import OrderRepository

    worker = await get_retry_worker()
    order_repo = OrderRepository()

    # Worker status
    worker_status = "Running" if worker._running else "Stopped"

    # Pending count
    pending_count = await order_repo.get_pending_count()

    # Retry stats
    stats = await order_repo.get_retry_stats(hours=1)

    # Worker metrics
    metrics = worker.get_metrics()

    success_rate_text = f"{stats['success_rate_pct']:.1f}%"

    # Get pending orders for table
    from datetime import datetime, timezone
    pending_orders = await order_repo.get_pending_retries(
        now=datetime.now(timezone.utc),
        limit=20
    )

    retry_rows = [
        [
            str(o.id)[:8],
            o.order_type.value,
            o.token_symbol,
            o.attempt_count,
            o.next_retry_at.strftime("%H:%M:%S") if o.next_retry_at else "Now"
        ]
        for o in pending_orders
    ]

    return (
        worker_status,
        pending_count,
        stats["total_retries"],
        success_rate_text,
        retry_rows,
    )
```

## Implementation Tasks

- [ ] Create RetryWorker class
- [ ] Implement polling loop with interval
- [ ] Add priority ordering (EXIT before ENTRY)
- [ ] Implement optimistic locking
- [ ] Handle lock timeout and cleanup
- [ ] Integrate with OrderExecutor
- [ ] Handle entry/exit filled callbacks
- [ ] Create critical alerts on max attempts
- [ ] Add startup/shutdown integration
- [ ] Create Gradio system health panel
- [ ] Collect and expose metrics
- [ ] Write unit tests
- [ ] Write integration tests

## Definition of Done

- [ ] Worker polls every 5 seconds
- [ ] EXIT orders processed before ENTRY
- [ ] Locking prevents double execution
- [ ] Max attempts creates critical alert
- [ ] Position created on entry fill
- [ ] Position updated on exit fill
- [ ] Metrics exposed for monitoring
- [ ] Graceful startup/shutdown
- [ ] Full test coverage

## File List

### New Files
- `src/walltrack/services/order/retry_worker.py` - Retry worker service
- `src/walltrack/ui/components/system_health.py` - Health display
- `tests/unit/services/order/test_retry_worker.py` - Worker tests
- `tests/integration/test_retry_flow.py` - Integration tests

### Modified Files
- `src/walltrack/data/supabase/repositories/order_repo.py` - Add retry queries
- `migrations/V9__orders.sql` - Add locking columns
- `src/walltrack/main.py` - Start/stop worker
- `src/walltrack/ui/pages/dashboard.py` - Add health panel
